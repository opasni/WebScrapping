{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a chrome options object so you can set the size and headless preference\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "\n",
    "chrome_driver = os.getcwd() +\"\\\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=chrome_driver)\n",
    "driver.get(\"https://www.bayern-international.de/en/company-database/\")\n",
    "\n",
    "# foldable_header = driver.find_element_by_class_name(name=\"foldable header\")\n",
    "foldable_header = driver.find_element_by_css_selector(\"div.foldable-container.keytech-search-form-extended.collapsed\");\n",
    "foldable_header.click()\n",
    "\n",
    "select = Select(driver.find_element_by_name(name=\"tx_keytechrenew_keytech[state_province]\"))\n",
    "select.select_by_value('091')\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "select_none = driver.find_element_by_css_selector(\"a.form-district-select-none\")\n",
    "select_none.click()\n",
    "\n",
    "list_of_districts = [\"form_district_09171\",\"form_district_09173\",\"form_district_09172\",\"form_district_09174\",\"form_district_09175\",\"form_district_09176\",\"form_district_09177\",\"form_district_09178\",\"form_district_09179\",\"form_district_09180\",\"form_district_09161\",\"form_district_09181\",\"form_district_09182\",\"form_district_09183\",\"form_district_09184\",\"form_district_09162\",\"form_district_09185\",\"form_district_09186\",\"form_district_09187\",\"form_district_09163\",\"form_district_09188\",\"form_district_09189\",\"form_district_09190\"]\n",
    "# We execute this twice, otherway it returns too many results\n",
    "for item in list_of_districts[:13]:\n",
    "    select_district = driver.find_element_by_id(item)\n",
    "    select_district.click()\n",
    "\n",
    "\n",
    "search_button = driver.find_element_by_name(name=\"tx_keytechrenew_keytech[search]\")\n",
    "search_button.click()\n",
    "\n",
    "# capture the screen\n",
    "driver.get_screenshot_as_file(\"capture.png\")\n",
    "# driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "n_of_pages = int(driver.find_element_by_xpath(\"//*[@id='keytech_list_result']/div[1]/nav/ul/li[5]/a\").text)\n",
    "\n",
    "# If executed the first time, otherwise, comment that!!!!!!!!!!!!!\n",
    "list_of_links = []\n",
    "\n",
    "for i in range(n_of_pages):\n",
    "    url = \"https://www.bayern-international.de/en/company-database/results/\" + str(i) + \"/\"\n",
    "    driver.get(url)\n",
    "    html_doc = driver.page_source\n",
    "    soup = BeautifulSoup(html_doc, \"lxml\")\n",
    "    a_tags = soup.find_all('a')\n",
    "    # Print the URLs to the shell\n",
    "    for link in a_tags:\n",
    "        if 'en/company-database/company-details/' in link.get('href'):\n",
    "            list_of_links.append(link.get('href').split('/')[-2])\n",
    "    time_to_wati = max(0, 1 + np.random.normal(0, 1))\n",
    "    time.sleep(time_to_wati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"list_of_links.txt\", 'w') as file:\n",
    "    file.writelines(\"\\n\".join(list_of_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"list_of_links.txt\", 'r') as file:\n",
    "    line = file.readlines()\n",
    "list_of_links = [li[:-1] for li in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to all the pages and parsing the data\n",
    "stand = 'https://www.bayern-international.de/en/company-database/company-details/'\n",
    "list_of_div = [\"//*[@id='content']/div/article/ul[2]/li[1]/div/dl[1]\",\"//*[@id='content']/div/article/ul[2]/li[1]/div/dl[2]\",\"//*[@id='content']/div/article/ul[2]/li[1]/dl[1]\"]\n",
    "all_info = []\n",
    "for i, item in enumerate(list_of_links[:4]):\n",
    "    url = stand + item\n",
    "    driver.get(url)\n",
    "    d = {}\n",
    "    list_of_labels = []\n",
    "    list_of_definitions = []\n",
    "    with open('progress_log.txt', 'a') as file:\n",
    "        file.write(\"\\nSite number: \" + str(i))\n",
    "        file.write(\"\\nSite name: \" + str(url))\n",
    "        try:\n",
    "            for path in list_of_div:\n",
    "                label = driver.find_element_by_xpath(path)\n",
    "                all_children_by_css = label.find_elements_by_css_selector(\"*\")\n",
    "                for item in all_children_by_css:\n",
    "                    attr = item.get_attribute(\"class\")\n",
    "                    text = item.text\n",
    "                    if 'Map' in text: break\n",
    "                    elif attr == 'label':\n",
    "                        list_of_labels.append(text)\n",
    "                    elif attr == 'definition':\n",
    "                        list_of_definitions.append(text)\n",
    "            for i, item in enumerate(list_of_labels):\n",
    "                d[item] = list_of_definitions[i]\n",
    "            all_info.append(d)\n",
    "            time_to_wati = max(0, 3 + np.random.normal(0, 1))\n",
    "            file.write(\"\\n\" + str(time_to_wati))\n",
    "            time.sleep(time_to_wati)\n",
    "        except:\n",
    "            file.write(\"\\nSomething went wrong.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we obtain the data it is time for the cleaning process. Because of German characters, we need to do some assumptions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I tried to replace, or ignore problematic characters. I would be better to clean them directly in the dataframe though, as we can always redo the changes\n",
    "def replace(values, searchFor):\n",
    "    for k in values:\n",
    "        for v in values[k]:\n",
    "            if searchFor in str(v):\n",
    "                print(\"Old form:\", values[k])\n",
    "                values[k] = values[k].replace('\\u0131', 'i')\n",
    "                values[k] = values[k].encode('latin-1', 'replace')\n",
    "                print(\"New form:\", values[k])\n",
    "for pr in problematic_characters:\n",
    "    print(\"Problematic is:\", pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we just search for characters\n",
    "def search(values, searchFor):\n",
    "    for k in values:\n",
    "        for v in values[k]:\n",
    "            if searchFor in v:\n",
    "                print(\"Original values:\", values[k])\n",
    "                print(\"If we ignore:\", values[k].encode('latin-1', 'ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for item in all_info:\n",
    "        search(item, '\\u2013')\n",
    "except:\n",
    "    print(\"There were no problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_characters = ['\\u2013', '\\u2022', '\\u202a', '\\u2019', '\\u202c','\\u0131']\n",
    "try:\n",
    "    for cha in problematic_characters:\n",
    "        for item in all_info:\n",
    "            replace(item, cha)\n",
    "except:\n",
    "    print(\"Some problems!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for the \"Sometging went worng\"! If there is missing data, add it to the list! (e.g. all_info.insert(2045,add_site_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DATAFRAME and add the links to sites\n",
    "df = pd.DataFrame(all_info)\n",
    "df[\"Bayer Internatinal Links\"] = list_of_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My cleaning script\n",
    "def number_clean(number):\n",
    "    if len(number)< 1:\n",
    "        clean = \"not available\"\n",
    "    elif len(number) < 8:\n",
    "        clean = \"not available\"\n",
    "#         print(number)\n",
    "    else:\n",
    "        clean = number\n",
    "    if clean[0] == 'b':\n",
    "        clean = clean[2:-1]\n",
    "    if clean[:2] == '49':\n",
    "        clean = '+' + clean\n",
    "    if clean[:4] == '0049':\n",
    "        clean = ('+49 ' + clean[4:])\n",
    "    if '.' in clean:\n",
    "        if 'bzw' not in clean:\n",
    "            clean = clean.replace('.', ' ')\n",
    "    clean = clean.replace('-', '')\n",
    "    clean = clean.replace('  ', ' ')\n",
    "    clean = clean.replace('(0)', '')\n",
    "    clean = clean.replace('(', '')\n",
    "    clean = clean.replace(')', '')\n",
    "    clean = clean.replace('/', '')\n",
    "    clean = clean.replace('  ', ' ')\n",
    "    clean = clean.replace('+ 49', '+49')\n",
    "    clean = clean.replace('+49', '+49 ')\n",
    "    clean = clean.replace('  ', ' ')\n",
    "    clean = clean.replace('++', '+')\n",
    "    clean = clean.replace('+0', '+')\n",
    "    if clean[:1] != '+':\n",
    "        if clean != 'not available':\n",
    "            clean = ('+49 ' + clean[1:]).replace('  ', ' ')\n",
    "    if clean[:2] == '+0':\n",
    "        clean = ('+49 ' + clean[2:])\n",
    "    return clean\n",
    "\n",
    "def format_number(number):\n",
    "    value = number.replace(' ', '').replace('+49', '+49 ').replace('+43', '+43 ').replace('+48', '+48 ').replace('+86', '+86 ').replace('+7', '+7 ').replace('+0', '+49 ')\n",
    "    parts = value.split(' ')\n",
    "    value = parts[0] + ' ' + parts[1][:4] + ' ' + parts[1][4:]\n",
    "    return value\n",
    "\n",
    "# Cleaning the phone and fax numbers (and formating them)\n",
    "string_to_clean = [\"Phone\", \"Fax\"]\n",
    "for item in string_to_clean:\n",
    "    for i in range(len(df[item])):\n",
    "        item_clean = number_clean(str(df[item][i]))\n",
    "        df[item][i] = item_clean\n",
    "        value = df[item][i]\n",
    "        if value != \"not available\":\n",
    "            if len(value) > 22:\n",
    "                value = value.replace('oder', '/').replace('bzw.', '/')\n",
    "                if '/' not in value:\n",
    "                    value = value.replace(' +49', ' / +49')\n",
    "            splits = value.split('/')\n",
    "            if len(splits) > 1:\n",
    "                splits[1] = splits[1].replace('kostenfrei', '').replace('  ', '')\n",
    "            for j in range(len(splits)):\n",
    "                splits[j] = number_clean(splits[j])\n",
    "                splits[j] = format_number(splits[j])\n",
    "            df[item][i] = ' / '.join(splits)\n",
    "        \n",
    "        \n",
    "for i in range(len(df[\"Contact person\"])):\n",
    "    if isinstance(df[\"Contact person\"][i], float):\n",
    "        df[\"Contact person\"][i] = \"not available\"\n",
    "        \n",
    "for item in df:\n",
    "    for i in range(len(df[item])):\n",
    "        if isinstance(df[item][i], str):\n",
    "            if len(df[item][i]) < 2:\n",
    "                df[item][i] = \"not available\"\n",
    "        else:\n",
    "            df[item][i] = df[item][i].decode(\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Upper_Bavaria_info.csv', sep=';', encoding='latin-1', index_label=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
